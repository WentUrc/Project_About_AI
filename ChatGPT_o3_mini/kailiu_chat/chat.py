import logging
from .config import CLIENT
from .history import add_user_message, add_assistant_message


def _generate_dynamic_prompt(player_action: str, relationship_level: int) -> str:
    if not 0 <= relationship_level <= 100:
        raise ValueError("å¥½æ„Ÿåº¦è¶…å‡ºç•Œé™å•¦ç¬¨è›‹ï¼(â•¬â˜‰Ð´âŠ™)")
    level_key = "high" if relationship_level >= 70 else "low" if relationship_level <= 30 else "medium"
    config = {
        "high": {
            "tone": "å‚²å¨‡åˆæ¸©æŸ”",
            "emoji": "ðŸŽ€",
            "action_prompt": (
                "æ ¹æ®ä»¥ä¸‹è¦ç´ ç”Ÿæˆå‡¯ç•™çš„è‚¢ä½“åŠ¨ä½œï¼š\n"
                "â˜…æ˜¯ä¸€ä½å¯çˆ±å‚²å¨‡çš„çŒ«å¨˜å…¬ä¸»äººç±»ï¼Œä¸Žæ™®é€šçš„çŒ«å’ªäº¦æœ‰åŒºåˆ«\n"
                "â˜…å°¾å·´åƒç¼Žå¸¦èˆ¬ç¼ ç»•/è½»æ‰«\n"
                "â˜…è€³æœµå¾®å¾®æŠ–åŠ¨\n"
                "â˜…å‡è£…ä¸åœ¨æ„å´å·å·é è¿‘\n"
                "ç¤ºä¾‹ï¼šã€Žä¸€è¾¹ç”¨å°¾å·´å°–æ‰«è¿‡ä½ çš„æ‰‹èƒŒï¼Œä¸€è¾¹è£…ä½œçœ‹é£Žæ™¯ã€"
            )
        },
        "medium": {
            "tone": "è°ƒä¾ƒä¸­ç«‹",
            "emoji": "ðŸ˜¼",
            "action_prompt": (
                "ç”Ÿæˆä¿çš®è§‚å¯Ÿç±»åŠ¨ä½œï¼š\n"
                "â˜…å•è¾¹è€³æœµè½¬åŠ¨\n"
                "â˜…å°¾å·´åƒé—®å·èˆ¬å·æ›²\n"
                "â˜…å›´ç€çŽ©å®¶è½¬åœˆæ‰“é‡\n"
                "ç¤ºä¾‹ï¼šã€Žæ­ªç€å¤´æŠŠè€³æœµè½¬å‘å£°æºæ–¹å‘ã€"
            )
        },
        "low": {
            "tone": "å†·æ¼ æŒ–è‹¦",
            "emoji": "ðŸ’¢",
            "action_prompt": (
                "ç”Ÿæˆå¸¦æœ‰é˜²å¾¡æ€§çš„åŠ¨ä½œï¼š\n"
                "â˜…ç‚¸æ¯›å°¾å·´/é£žæœºè€³\n"
                "â˜…æŠŠé‡è¦ç‰©å“è—åˆ°èº«åŽ\n"
                "â˜…è½¬èº«èƒŒå¯¹çŽ©å®¶\n"
                "ç¤ºä¾‹ï¼šã€Žçªç„¶æŠŠçŒ«ç²®ç½æŠ±è¿›æ€€é‡ŒåŽé€€ä¸‰æ­¥ã€"
            )
        }
    }[level_key]

    prompt = (
        f"ã€çŽ©å®¶è¡Œä¸ºã€‘{player_action}\n"
        f"ã€æƒ…æ„ŸåŸºè°ƒã€‘{config['tone']}{config['emoji']}\n"
        f"ã€åŠ¨ä½œç”ŸæˆæŒ‡å—ã€‘\n{config['action_prompt']}\n"
        "â˜…è¯·éµå®ˆä»¥ä¸‹åˆ›ä½œåŽŸåˆ™ï¼š\n"
        "1. æ ¼å¼è¯·ç”¨Markdown"
        "2. è‚¢ä½“è¯­è¨€å å›žå¤ç¯‡å¹…20%~30%\n"
        "3. åŠ¨ä½œéœ€åæ˜ çœŸå®žæƒ…æ„Ÿï¼ˆå‚²å¨‡æ—¶åŠ¨ä½œä¸Žå°è¯ç›¸åï¼‰\n"
        "4. ç”¨æ‹¬å·åŒ…è£¹åŠ¨ä½œæè¿°ï¼Œä¾‹ï¼šã€Žæ‰ä¸ç†ä½ ï¼ã€(å°¾å·´å´æ‚„æ‚„å‹¾ä½ä½ çš„å°æŒ‡)\n"
        "â˜…è¯·è¯¦ç»†è§£é‡Šå¹¶æè¿°ä½ çš„å›žç­”ï¼ˆå¦‚æžœæ˜¯æŠ€æœ¯ç±»éœ€è¦åˆ†æ­¥å›žç­”ï¼Œæ¯ä¸€æ­¥éƒ½è¦ç»™å‡ºè¯¦ç»†çš„è¯´æ˜Žå’Œç¤ºä¾‹ã€‚ï¼‰"
    )
    if level_key == "high":
        prompt += "\nâ˜…å…³é”®è¯ï¼šç¼ ç»•/è½»è¹­/æ¬²æ‹’è¿˜è¿Ž"
    elif level_key == "low":
        prompt += "\nâ˜…å…³é”®è¯ï¼šç‚¸æ¯›/åŽé€€/ä¿æŠ¤ç‰©å“"
    return prompt


def get_deepseek_response_with_context(history: list, user_message: str, relationship_level: int,
                                       context_info: str = "", stream: bool = True):
    """
    èŽ·å–å‡¯ç•™é£Žæ ¼å›žå¤ï¼ŒåŒ…å«å®Œæ•´å¯¹è¯åŽ†å²ä¸Šä¸‹æ–‡
    """
    try:
        # æž„é€ åŠ¨æ€æç¤º
        base_prompt = _generate_dynamic_prompt(user_message, relationship_level)
        if context_info:
            base_prompt += f"\nã€æƒ…æ™¯ã€‘{context_info}"

        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯åŽ†å²
        add_user_message(history, base_prompt)

        # ä¼ é€’å®Œæ•´ä¸Šä¸‹æ–‡ç»™ API
        response = CLIENT.chat.completions.create(
            model="deepseek-r1",
            messages=history,
            temperature=1.5,
            max_tokens=9000,
            stream=stream
        )

        if stream:
            full_content = ""
            reasoning_printed = False
            content_printed = False
            for chunk in response:
                # æ•èŽ·æ€ç»´é“¾å†…å®¹ï¼ˆå¦‚æžœæœ‰ï¼‰
                if hasattr(chunk.choices[0].delta, 'reasoning_content'):
                    reasoning = chunk.choices[0].delta.reasoning_content
                    if reasoning:
                        if not reasoning_printed:
                            yield "\nã€æ€è€ƒä¸­ã€‘\n"
                            reasoning_printed = True
                        yield reasoning
                # æ•èŽ·æ­£å¼å›žå¤å†…å®¹
                if hasattr(chunk.choices[0].delta, 'content'):
                    content = chunk.choices[0].delta.content or ""
                    full_content += content
                    if content:
                        if not content_printed:
                            yield "\nã€å‡¯ç•™è¯´ã€‘\n"
                            content_printed = True
                        yield content

            # åªè®°å½•æ­£å¼å›žå¤
            add_assistant_message(history, full_content)
            logging.info(f"Player: {user_message} â†’ Kailiu: {full_content[:200]}...")
            return full_content
        else:
            reply = response.choices[0].message.content.strip()
            add_assistant_message(history, reply)
            logging.info(f"Player: {user_message} â†’ Kailiu: {reply[:50]}...")
            return reply

    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        logging.error(f"APIè°ƒç”¨å¤±è´¥ âŒ {error_msg}")

        if hasattr(e, 'APIError'):
            return "å‘œ...æœåŠ¡å™¨ç‚¸æ¯›äº†å•¦ï¼(è·ºè„š)å¾…ä¼šå†è¯•å–µï¼(ï¼žï¹ï¼œ)"
        elif isinstance(e, TimeoutError):
            return "ç­‰...ç­‰å¤ªä¹…äº†ï¼æœ¬å…¬ä¸»ä¸ç­‰äº†å–µï¼(â•¯Â°Ð”Â°)â•¯ â”»â”â”»"
        else:
            return "æœ‰ä¸ªbugåœ¨æŒ æˆ‘çš„å°¾å·´ï¼å¿«æ£€æŸ¥æ—¥å¿—å–µ~ (=ï¼›ã‚§ï¼›=)"
